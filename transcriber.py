from faster_whisper import WhisperModel
import os
import time


def transcribe_audio(audio_path, model_size="medium", device="auto", language=None, output_format="text"):
    """
    ä½¿ç”¨ faster-whisper è½¬å½•éŸ³é¢‘

    å‚æ•°:
        audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
        model_size: æ¨¡å‹å¤§å° ('tiny', 'base', 'small', 'medium', 'large-v3')
        device: è®¾å¤‡é€‰æ‹© ('auto', 'cpu', 'cuda')
        language: è¯­è¨€ä»£ç ï¼ˆNone è¡¨ç¤ºè‡ªåŠ¨æ£€æµ‹ï¼Œ'zh' ä¸­æ–‡ï¼Œ'en' è‹±æ–‡ï¼‰
        output_format: è¾“å‡ºæ ¼å¼ ('text', 'srt', 'vtt')

    è¿”å›:
        è½¬å½•æ–‡æœ¬å­—ç¬¦ä¸²ï¼Œå¤±è´¥è¿”å› None
    """
    if not os.path.exists(audio_path):
        print(f"âŒ é”™è¯¯: éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {audio_path}")
        return None

    # è·å–æ–‡ä»¶å¤§å°
    file_size = os.path.getsize(audio_path) / 1024 / 1024  # MB
    print(f"ğŸ“ éŸ³é¢‘æ–‡ä»¶: {os.path.basename(audio_path)}")
    print(f"ğŸ“Š æ–‡ä»¶å¤§å°: {file_size:.2f} MB")

    # è‡ªåŠ¨åˆ¤æ–­è®¾å¤‡
    if device == "auto":
        import torch
        device = "cuda" if torch.cuda.is_available() else "cpu"

    # æ ¹æ®è®¾å¤‡é€‰æ‹©è®¡ç®—ç²¾åº¦
    compute_type = "float16" if device == "cuda" else "int8"

    print(f"ğŸ§  æ­£åœ¨åŠ è½½æ¨¡å‹: {model_size}")
    print(f"ğŸš€ è¿è¡Œè®¾å¤‡: {device} (ç²¾åº¦: {compute_type})")

    # åŠ è½½æ¨¡å‹ï¼ˆé¦–æ¬¡è¿è¡Œä¼šè‡ªåŠ¨ä¸‹è½½ï¼‰
    start_load = time.time()
    try:
        model = WhisperModel(model_size, device=device, compute_type=compute_type)
        load_time = time.time() - start_load
        print(f"âœ… æ¨¡å‹åŠ è½½å®Œæˆ (è€—æ—¶: {load_time:.2f}s)")
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return None

    print("ğŸ™ï¸ å¼€å§‹è½¬å½•ï¼Œè¯·ç¨å€™...")
    start_time = time.time()

    try:
        # è½¬å½•éŸ³é¢‘
        # beam_size: æŸæœç´¢å¤§å°ï¼Œè¶Šå¤§è¶Šå‡†ç¡®ä½†è¶Šæ…¢
        segments, info = model.transcribe(
            audio_path,
            beam_size=5,
            language=language,
            task="transcribe"  # 'transcribe' æˆ– 'translate'
        )

        # æ˜¾ç¤ºæ£€æµ‹åˆ°çš„è¯­è¨€
        print(f"ğŸŒ æ£€æµ‹åˆ°è¯­è¨€: {info.language} (ç½®ä¿¡åº¦: {info.language_probability:.2%})")

        results = []
        segment_count = 0

        # å¤„ç†æ¯ä¸ªç‰‡æ®µ
        for segment in segments:
            segment_count += 1

            # æ ¼å¼åŒ–æ—¶é—´æˆ³
            start_str = format_timestamp(segment.start)
            end_str = format_timestamp(segment.end)

            # æ ¹æ®è¾“å‡ºæ ¼å¼ç”Ÿæˆæ–‡æœ¬
            if output_format == "srt":
                # SRT å­—å¹•æ ¼å¼
                line = f"{segment_count}\n{start_str} --> {end_str}\n{segment.text.strip()}\n"
            elif output_format == "vtt":
                # WebVTT å­—å¹•æ ¼å¼
                line = f"{start_str} --> {end_str}\n{segment.text.strip()}\n"
            else:
                # é»˜è®¤æ–‡æœ¬æ ¼å¼ï¼ˆå¸¦æ—¶é—´æˆ³ï¼‰
                line = f"[{start_str} -> {end_str}] {segment.text.strip()}"

            # å®æ—¶æ‰“å°ï¼ˆæ¯ 10 ä¸ªç‰‡æ®µæ˜¾ç¤ºä¸€æ¬¡è¿›åº¦ï¼‰
            if segment_count % 10 == 0:
                print(f"ğŸ“ å·²å¤„ç† {segment_count} ä¸ªç‰‡æ®µ...")

            results.append(line)

        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        elapsed_time = time.time() - start_time
        audio_duration = segment.end if segment_count > 0 else 0
        speed_ratio = audio_duration / elapsed_time if elapsed_time > 0 else 0

        print(f"\nâœ… è½¬å½•å®Œæˆ!")
        print(f"ğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
        print(f"   - æ€»ç‰‡æ®µæ•°: {segment_count}")
        print(f"   - éŸ³é¢‘æ—¶é•¿: {format_duration(audio_duration)}")
        print(f"   - è½¬å½•è€—æ—¶: {format_duration(elapsed_time)}")
        print(f"   - å¤„ç†é€Ÿåº¦: {speed_ratio:.2f}x å®æ—¶é€Ÿåº¦")

        # ç»„åˆç»“æœ
        if output_format == "srt":
            return "\n".join(results)
        elif output_format == "vtt":
            return "WEBVTT\n\n" + "\n".join(results)
        else:
            return "\n".join(results)

    except Exception as e:
        print(f"âŒ è½¬å½•å¤±è´¥: {e}")
        return None


def format_timestamp(seconds):
    """
    å°†ç§’æ•°æ ¼å¼åŒ–ä¸ºæ—¶é—´æˆ³å­—ç¬¦ä¸²

    å‚æ•°:
        seconds: ç§’æ•°ï¼ˆæµ®ç‚¹æ•°ï¼‰

    è¿”å›:
        æ ¼å¼åŒ–çš„æ—¶é—´æˆ³ (HH:MM:SS.mmm æˆ– HH:MM:SS,mmm for SRT)
    """
    hours = int(seconds // 3600)
    minutes = int((seconds % 3600) // 60)
    secs = int(seconds % 60)
    millis = int((seconds % 1) * 1000)

    return f"{hours:02d}:{minutes:02d}:{secs:02d}.{millis:03d}"


def format_duration(seconds):
    """
    å°†ç§’æ•°æ ¼å¼åŒ–ä¸ºå¯è¯»çš„æ—¶é•¿å­—ç¬¦ä¸²

    å‚æ•°:
        seconds: ç§’æ•°ï¼ˆæµ®ç‚¹æ•°ï¼‰

    è¿”å›:
        æ ¼å¼åŒ–çš„æ—¶é•¿å­—ç¬¦ä¸²
    """
    if seconds < 60:
        return f"{seconds:.1f}ç§’"
    elif seconds < 3600:
        minutes = int(seconds // 60)
        secs = int(seconds % 60)
        return f"{minutes}åˆ†{secs}ç§’"
    else:
        hours = int(seconds // 3600)
        minutes = int((seconds % 3600) // 60)
        return f"{hours}å°æ—¶{minutes}åˆ†"


if __name__ == "__main__":
    # ç®€å•çš„å‘½ä»¤è¡Œæµ‹è¯•
    import argparse

    parser = argparse.ArgumentParser(
        description="éŸ³é¢‘è½¬æ–‡å­—å·¥å…·",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  # åŸºæœ¬ç”¨æ³•
  python transcriber.py audio.mp3

  # æŒ‡å®šæ¨¡å‹å¤§å°
  python transcriber.py audio.mp3 --model small

  # æŒ‡å®šè¯­è¨€ï¼ˆè·³è¿‡è‡ªåŠ¨æ£€æµ‹ï¼‰
  python transcriber.py audio.mp3 --language zh

  # ç”Ÿæˆ SRT å­—å¹•æ–‡ä»¶
  python transcriber.py audio.mp3 --format srt -o output.srt
        """
    )

    parser.add_argument("audio_file", help="éŸ³é¢‘æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--model", default="medium",
                        choices=["tiny", "base", "small", "medium", "large-v3"],
                        help="æ¨¡å‹å¤§å°ï¼ˆé»˜è®¤: mediumï¼‰")
    parser.add_argument("--language", default=None,
                        help="è¯­è¨€ä»£ç ï¼ˆzh=ä¸­æ–‡, en=è‹±æ–‡, None=è‡ªåŠ¨æ£€æµ‹ï¼‰")
    parser.add_argument("--format", default="text",
                        choices=["text", "srt", "vtt"],
                        help="è¾“å‡ºæ ¼å¼ï¼ˆé»˜è®¤: textï¼‰")
    parser.add_argument("-o", "--output", default=None,
                        help="è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤: éŸ³é¢‘æ–‡ä»¶å_transcript.txtï¼‰")

    args = parser.parse_args()

    # è½¬å½•
    result = transcribe_audio(
        audio_path=args.audio_file,
        model_size=args.model,
        language=args.language,
        output_format=args.format
    )

    if result:
        # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
        if args.output:
            output_file = args.output
        else:
            base_name = os.path.splitext(os.path.basename(args.audio_file))[0]
            ext = "srt" if args.format == "srt" else "vtt" if args.format == "vtt" else "txt"
            output_file = f"{base_name}_transcript.{ext}"

        # ä¿å­˜ç»“æœ
        try:
            with open(output_file, "w", encoding="utf-8") as f:
                f.write(result)
            print(f"\nğŸ’¾ ç»“æœå·²ä¿å­˜: {output_file}")
        except Exception as e:
            print(f"\nâŒ ä¿å­˜å¤±è´¥: {e}")
            exit(1)
    else:
        print("\nğŸ’” è½¬å½•å¤±è´¥")
        exit(1)
